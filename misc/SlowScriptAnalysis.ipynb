{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating Slow Scripts, Can we identify contributing add-ons?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the notebook as usual to get to our clean dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# E10s testing for Beta 51 week 6: Main analysis\n",
    "\n",
    "(This covers data from 2016-12-28 to 2017-01-04 on Beta 51)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/home/hadoop/anaconda2/lib/python2.7/site-packages/matplotlib/__init__.py:878: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse whitelist (/home/hadoop/anaconda2/lib/python2.7/site-packages/moztelemetry/histogram-whitelists.json). Assuming all histograms are acceptable.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import ujson as json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import plotly.plotly as py\n",
    "import IPython\n",
    "import pyspark.sql.functions as fun\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from __future__ import division\n",
    "from moztelemetry.spark import get_pings, get_one_ping_per_client, get_pings_properties\n",
    "from montecarlino import grouped_permutation_test\n",
    "\n",
    "%pylab inline\n",
    "IPython.core.pylabtools.figsize(16, 7)\n",
    "seaborn.set_style('whitegrid')\n",
    "\n",
    "from operator import add\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'1.6.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chi2_distance(xs, ys, eps = 1e-10, normalize = True):\n",
    "    \"\"\" The comparison metric for histograms. \"\"\"\n",
    "    histA = xs.sum(axis=0)\n",
    "    histB = ys.sum(axis=0)\n",
    "    \n",
    "    if normalize:\n",
    "        histA = histA/histA.sum()\n",
    "        histB = histB/histB.sum()\n",
    "    \n",
    "    d = 0.5 * np.sum([((a - b) ** 2) / (a + b + eps)\n",
    "        for (a, b) in zip(histA, histB)])\n",
    "\n",
    "    return d\n",
    "\n",
    "def median_diff(xs, ys):\n",
    "    return np.median(xs) - np.median(ys)\n",
    "\n",
    "def make_group_histogram(group_data):\n",
    "    \"\"\" Combine separate client histograms into a single group histogram, normalizing bin counts\n",
    "        to relative frequencies.       \n",
    "    \"\"\"\n",
    "    ## Check for histograms with 0 counts.\n",
    "    client_totals = group_data.map(lambda x: x.sum())\n",
    "    group_data = group_data[client_totals > 0]\n",
    "    ## Convert frequency counts to relative frequency for each client histogram.\n",
    "    group_data = group_data.map(lambda x: x/x.sum())\n",
    "    ## Merge the group's client histograms by adding up the frequencies over all clients\n",
    "    ## in the group, separately for each bin.\n",
    "    group_data = group_data.sum()\n",
    "    ## Convert the merged bin frequencies to relative percentages.\n",
    "    group_data = 100 * group_data / group_data.sum()\n",
    "    return group_data\n",
    "    \n",
    "\n",
    "def compare_histogram(histogram, e10s_addons, none10s_addons, e10s_std=None, none10s_std=None,\n",
    "                      include_diff=True, include_diff_in_diff=True, did_separate_plot=True):\n",
    "    \"\"\" Compare an e10s histogram to a non-e10s one, and graph the results.\n",
    "        \n",
    "        Plots the two histograms overlaid on the same graph, and prints a p-value\n",
    "        for testing whether they are different. If 'include_diff' is True, also\n",
    "        draw a plot of the frequency differences for each bin.\n",
    "        \n",
    "        If 'include_diff_in_diff' is True and data is supplied, include a plot of\n",
    "        differences between addon cohort differences and non-addon cohort differences.\n",
    "    \"\"\"\n",
    "    eTotal = make_group_histogram(e10s_addons)\n",
    "    nTotal = make_group_histogram(none10s_addons)\n",
    "    \n",
    "    if include_diff:\n",
    "        if include_diff_in_diff and did_separate_plot:\n",
    "            fig, (ax, diff_ax, diff_diff_ax) = plt.subplots(3, sharex=True, figsize=(16,10), \n",
    "                                                            gridspec_kw={\"height_ratios\": [2,2,1]})\n",
    "        else:\n",
    "            fig, (ax, diff_ax) = plt.subplots(2, sharex=True)\n",
    "    else:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        \n",
    "    fig.subplots_adjust(hspace=0.3)\n",
    "    ax2 = ax.twinx()\n",
    "    width = 0.4\n",
    "    ylim = max(eTotal.max(), nTotal.max())\n",
    "        \n",
    "    eTotal.plot(kind=\"bar\", alpha=0.5, color=\"green\", label=\"e10s\", ax=ax, width=width,\n",
    "                position=0, ylim=(0, ylim + 1))\n",
    "    nTotal.plot(kind=\"bar\", alpha=0.5, color=\"blue\", label=\"non-e10s\", ax=ax2, width=width,\n",
    "                position=1, grid=False, ylim=ax.get_ylim())\n",
    "    \n",
    "    ## Combine legend info from both Axes.\n",
    "    ax_h, ax_l = ax.get_legend_handles_labels()\n",
    "    ax2_h, ax2_l = ax2.get_legend_handles_labels()\n",
    "    ax.legend(ax_h + ax2_h, ax_l + ax2_l, loc = 0)\n",
    " \n",
    "    plt.title(histogram)\n",
    "    ax.xaxis.grid(False)\n",
    "    ax.set_ylabel(\"Frequency %\")\n",
    "\n",
    "    if include_diff:\n",
    "        ## Add a second barplot of the difference in frequency for each bucket.\n",
    "        #diff_ax = fig.add_subplot(2, 1, 2)\n",
    "        enDiff = eTotal - nTotal\n",
    "        \n",
    "        has_diff_in_diff_data = (e10s_std is not None and len(e10s_std) > 0 and\n",
    "                                 none10s_std is not None and len(none10s_std) > 0)\n",
    "        if include_diff_in_diff and has_diff_in_diff_data:\n",
    "            ## Add bin differences for between e10s/non-e10s for the no-addons cohorts.\n",
    "            ## The assumption is that the difference between addons cohorts would look the same\n",
    "            ## if there is no additional effect of having addons.\n",
    "            eTotal_std = make_group_histogram(e10s_std)\n",
    "            nTotal_std = make_group_histogram(none10s_std)\n",
    "            enDiff_std = eTotal_std - nTotal_std\n",
    "            ylims = (min(enDiff.min(), enDiff_std.min()) - 0.5, max(enDiff.max(), enDiff_std.max()) + 0.5)\n",
    "            diff_ax2 = diff_ax.twinx()\n",
    "            \n",
    "            enDiff.plot(kind=\"bar\", alpha=0.5, color=\"navy\", label=\"with add-ons\", ax=diff_ax, width=width,\n",
    "                        position=1, ylim=ylims)\n",
    "            enDiff_std.plot(kind=\"bar\", alpha=0.5, color=\"gray\", label=\"no add-ons\", ax=diff_ax2, width=width,\n",
    "                        position=0, grid=False, ylim=diff_ax.get_ylim())\n",
    "\n",
    "            ## Combine legend info from both Axes.\n",
    "            diff_ax_h, diff_ax_l = diff_ax.get_legend_handles_labels()\n",
    "            diff_ax2_h, diff_ax2_l = diff_ax2.get_legend_handles_labels()\n",
    "            leg_h = diff_ax_h + diff_ax2_h\n",
    "            leg_l = diff_ax_l + diff_ax2_l\n",
    "            \n",
    "            if did_separate_plot:\n",
    "                enDiffDiff = enDiff - enDiff_std\n",
    "                enDiffDiff.plot(kind=\"bar\", alpha=0.5, color=\"maroon\", ax=diff_diff_ax, ylim=diff_ax.get_ylim())\n",
    "                diff_diff_ax.xaxis.grid(False)\n",
    "                diff_diff_ax.set_ylabel(\"Diff in freq %\")\n",
    "                diff_diff_ax.set_title(\"Diff between e10s/non diff with add-ons and e10s/non diff without\" +\n",
    "                                      \" (with add-ons higher when > 0)\")\n",
    "            \n",
    "        else:\n",
    "            if include_diff_in_diff:\n",
    "                ## We wanted to do the additional comparison, but there wasn't enough data.\n",
    "                print(\"\\nNo diff-in-diff comparison: one of the standard cohorts has no non-missing observations.\")\n",
    "            enDiff.plot(kind=\"bar\", alpha=0.5, color=\"navy\", label=\"with add-ons\", ax=diff_ax)\n",
    "            leg_h, leg_l = diff_ax.get_legend_handles_labels()\n",
    "        \n",
    "        plt.title(\"e10s/non-e10s difference (more e10s in bucket when > 0)\")\n",
    "        diff_ax.xaxis.grid(False)\n",
    "        diff_ax.set_ylabel(\"Diff in frequency %\")\n",
    "        diff_ax.legend(leg_h, leg_l, loc = 0)\n",
    "    \n",
    "    \n",
    "    # Only display at most 100 tick labels on the x axis.\n",
    "    xticklabs = plt.gca().get_xticklabels()\n",
    "    max_x_ticks = 100\n",
    "    if len(xticklabs) > max_x_ticks:\n",
    "        step_size = math.ceil(float(len(xticklabs)) / max_x_ticks)\n",
    "        for i, tl in enumerate(xticklabs):\n",
    "            if i % step_size != 0:\n",
    "                tl.set_visible(False)\n",
    "    plt.show()\n",
    "    \n",
    "    ## Compute a p-value for the chi-square distance between the groups' combined histograms.\n",
    "    pvalue = grouped_permutation_test(chi2_distance, [e10s_addons, none10s_addons], num_samples=100)\n",
    "    print(\"The probability that the distributions for {} (with add-ons) are differing by chance is {:.3f}.\"\\\n",
    "          .format(histogram, pvalue))\n",
    "\n",
    "def normalize_uptime_hour(frame):\n",
    "    \"\"\" Convert metrics to rates per hour of uptime. \"\"\"\n",
    "    frame = frame[frame[\"payload/simpleMeasurements/totalTime\"] > 60]\n",
    "    frame = 60 * 60 * frame.apply(lambda x: x / frame[\"payload/simpleMeasurements/totalTime\"]) # Metric per hour\n",
    "    frame.drop('payload/simpleMeasurements/totalTime', axis=1, inplace=True)\n",
    "    return frame\n",
    "    \n",
    "def compare_e10s_count_histograms(pings, cohort_sizes = {}, *histogram_names, **kwargs):\n",
    "    \"\"\" Read multiple count histograms from a collection of pings, and compare e10s/non-e10s for each.\n",
    "    \n",
    "        Treats count histograms as scalars for comparison purposes, without distinguishing between\n",
    "        parent and child processes. Expects a dict containing overall cohort sizes\n",
    "        for computing sample size proportions.\n",
    "    \"\"\"\n",
    "    properties = histogram_names + (\"payload/simpleMeasurements/totalTime\", \"e10s\", \"addons\")\n",
    "    frame = pd.DataFrame(get_pings_properties(pings, properties).collect())\n",
    "    \n",
    "    e10s = frame[frame[\"addons\"] & frame[\"e10s\"]]\n",
    "    e10s = normalize_uptime_hour(e10s)\n",
    "    \n",
    "    none10s = frame[frame[\"addons\"] & ~frame[\"e10s\"]]\n",
    "    none10s = normalize_uptime_hour(none10s)\n",
    "    \n",
    "    include_diff_in_diff = kwargs.get(\"include_diff_in_diff\", True)\n",
    "    if include_diff_in_diff:\n",
    "        e10s_std = normalize_uptime_hour(frame[~frame[\"addons\"] & frame[\"e10s\"]])\n",
    "        none10s_std = normalize_uptime_hour(frame[~frame[\"addons\"] & ~frame[\"e10s\"]])        \n",
    "    \n",
    "    for histogram in histogram_names:\n",
    "        if histogram not in none10s.columns:\n",
    "            continue\n",
    "        \n",
    "        ## Remove the property path from the histogram name for display purposes.\n",
    "        hist_name = hist_base_name(histogram)\n",
    "        if type(hist_name) == list:\n",
    "            ## Key was given for keyed histogram.\n",
    "            hist_str = \"{}/{}\".format(link_to_histogram(hist_name[0]), hist_name[1])\n",
    "            hist_name = hist_name[0]\n",
    "        else:\n",
    "            hist_str = hist_name\n",
    "        ## Print a header for the block of graphs, including a link to the histogram definition.\n",
    "        print_with_markdown(\"Comparison for count histogram {} (with add-ons):\".format(hist_str))\n",
    "        \n",
    "        e10s_hist = e10s[histogram].dropna()\n",
    "        non_e10s_hist = none10s[histogram].dropna()\n",
    "        \n",
    "        ## Print some information on sample sizes.\n",
    "        print(\"{} non-e10s profiles have this histogram.\".format(\n",
    "                sample_size_str(len(non_e10s_hist), cohort_sizes.get(\"addons-set2a-control\"))))\n",
    "        print(\"{} e10s profiles have this histogram.\".format(\n",
    "                sample_size_str(len(e10s_hist), cohort_sizes.get(\"addons-set2a-test\"))))\n",
    "        ## If either group has no data, nothing more to do.\n",
    "        if len(non_e10s_hist) == 0 or len(e10s_hist) == 0:\n",
    "            continue\n",
    "        \n",
    "        print(\"\")\n",
    "        compare_scalars(hist_name + \" per hour\", e10s_hist, non_e10s_hist,\n",
    "                        e10s_std[histogram].dropna() if include_diff_in_diff else None,\n",
    "                        none10s_std[histogram].dropna() if include_diff_in_diff else None)\n",
    " \n",
    "def compare_e10s_histograms(pings, cohort_sizes = {}, *histogram_names, **kwargs):\n",
    "    \"\"\" Read multiple histograms from a collection of pings, and compare e10s/non-e10s for each.\n",
    "    \n",
    "        Outputs separate comparisons for parent process, child processes, and merged histograms.\n",
    "        Expects a dict containing overall cohort sizes for computing sample\n",
    "        size proportions.\n",
    "    \"\"\"\n",
    "    ## Load histogram data from the ping set, separating parent & child processes for e10s.\n",
    "    frame = pd.DataFrame(get_pings_properties(pings, histogram_names + (\"e10s\", \"addons\") , with_processes=True)\\\n",
    "        .collect())\n",
    "    ## The addons experiment cohorts.\n",
    "    e10s_addons = frame[frame[\"addons\"] & frame[\"e10s\"]]\n",
    "    none10s_addons = frame[frame[\"addons\"] & ~frame[\"e10s\"]]\n",
    "    ## The standard experiment cohorts.\n",
    "    e10s_std = frame[~frame[\"addons\"] & frame[\"e10s\"]]\n",
    "    none10s_std = frame[~frame[\"addons\"] & ~frame[\"e10s\"]]\n",
    "    \n",
    "    for histogram in histogram_names:\n",
    "        if histogram not in none10s_addons.columns:\n",
    "            continue\n",
    "        \n",
    "        ## Remove the property path from the histogram name for display purposes.\n",
    "        hist_name = hist_base_name(histogram)\n",
    "        if type(hist_name) == list:\n",
    "            ## Key was given for keyed histogram.\n",
    "            hist_str = \"{}/{}\".format(link_to_histogram(hist_name[0]), hist_name[1])\n",
    "            hist_name = hist_name[0]\n",
    "        else:\n",
    "            hist_str = hist_name\n",
    "        ## Print a header for the block of graphs, including a link to the histogram definition.\n",
    "        print_with_markdown(\"Comparison for {} (with add-ons):\".format(hist_str))\n",
    "        \n",
    "        ## Compare the main histogram for non-e10s against each of 3 for e10s.\n",
    "        addons_hist_data = {\n",
    "            \"non_e10s\": none10s_addons[histogram],\n",
    "            \"e10s_merged\": e10s_addons[histogram],\n",
    "            \"e10s_parent\": e10s_addons[histogram + \"_parent\"],\n",
    "            \"e10s_children\": e10s_addons[histogram + \"_children\"]\n",
    "        }\n",
    "        for htype in addons_hist_data:\n",
    "            addons_hist_data[htype] = addons_hist_data[htype].dropna()\n",
    "        \n",
    "        ## Print some information on sample sizes.\n",
    "        sample_sizes = { htype: len(hdata) for htype, hdata in addons_hist_data.iteritems() }\n",
    "        print(\"{} non-e10s profiles have this histogram.\".format(\n",
    "                sample_size_str(sample_sizes[\"non_e10s\"], cohort_sizes.get(\"addons-set2a-control\"))))\n",
    "        print(\"{} e10s profiles have this histogram.\".format(\n",
    "                sample_size_str(sample_sizes[\"e10s_merged\"], cohort_sizes.get(\"addons-set2a-test\"))))\n",
    "        ## If either group has no data, nothing more to do.\n",
    "        if sample_sizes[\"non_e10s\"] == 0 or sample_sizes[\"e10s_merged\"] == 0:\n",
    "            continue\n",
    "        \n",
    "        print(\"{} e10s profiles have the parent histogram.\".format(\n",
    "                sample_size_str(sample_sizes[\"e10s_parent\"], cohort_sizes.get(\"addons-set2a-test\"))))\n",
    "        print(\"{} e10s profiles have the children histogram.\".format(\n",
    "                sample_size_str(sample_sizes[\"e10s_children\"], cohort_sizes.get(\"addons-set2a-test\"))))\n",
    "        \n",
    "        has_parent = sample_sizes[\"e10s_parent\"] > 0\n",
    "        has_children = sample_sizes[\"e10s_children\"] > 0\n",
    "        \n",
    "        non_e10s_std_hist = none10s_std[histogram].dropna()\n",
    "        \n",
    "        ## Compare merged histograms, unless e10s group has either no parents or no children.\n",
    "        if has_children and has_parent:\n",
    "            compare_histogram(hist_name + \" (e10s merged)\", \n",
    "                              addons_hist_data[\"e10s_merged\"],\n",
    "                              addons_hist_data[\"non_e10s\"],\n",
    "                              e10s_std[histogram].dropna(),\n",
    "                              non_e10s_std_hist,\n",
    "                              **kwargs)\n",
    "        \n",
    "        if has_parent:\n",
    "            compare_histogram(hist_name + \" (parent)\",\n",
    "                              addons_hist_data[\"e10s_parent\"],\n",
    "                              addons_hist_data[\"non_e10s\"],\n",
    "                              e10s_std[histogram + \"_parent\"].dropna(),\n",
    "                              non_e10s_std_hist,\n",
    "                              **kwargs)\n",
    "\n",
    "        if has_children:\n",
    "            compare_histogram(hist_name + \" (children)\",\n",
    "                              addons_hist_data[\"e10s_children\"],\n",
    "                              addons_hist_data[\"non_e10s\"],\n",
    "                              e10s_std[histogram + \"_children\"].dropna(),\n",
    "                              non_e10s_std_hist,\n",
    "                              **kwargs)\n",
    "\n",
    "def compare_scalars(metric, e10s_data, non_e10s_data, e10s_std=None, non_e10s_std=None, unit=\"units\"):\n",
    "    \"\"\" Prints info about the median difference between the groups, together with a p-value\n",
    "        for testing the difference.\n",
    "        \n",
    "        Optionally include a string indicating the units the metric is measured in.\n",
    "        If data is supplied, also print a comparison for non-addons cohorts.\n",
    "    \"\"\"\n",
    "    e10s_data = e10s_data.dropna()\n",
    "    non_e10s_data = non_e10s_data.dropna()\n",
    "    if len(e10s_data) == 0 or len(non_e10s_data) == 0:\n",
    "        print(\"Cannot run comparison: one of the groups has no non-missing observations.\")\n",
    "        return\n",
    "    \n",
    "    print(\"Comparison for {}{} (with add-ons):\\n\".format(metric, \" ({})\".format(unit) if unit != \"units\" else \"\"))\n",
    "    e10s_median = np.median(e10s_data)\n",
    "    non_e10s_median = np.median(non_e10s_data)\n",
    "    mdiff = median_diff(e10s_data, non_e10s_data)\n",
    "    print(\"- Median with e10s is {:.3g} {} {} median without e10s.\"\\\n",
    "         .format(\n",
    "            #abs(mdiff),\n",
    "            mdiff,\n",
    "            unit,\n",
    "            #\"higher than\" if mdiff >= 0 else \"lower than\"\n",
    "            \"different from\"))\n",
    "    print(\"- This is a relative difference of {:.1f}%.\".format(float(mdiff) / non_e10s_median * 100))\n",
    "    print(\"- E10s group median is {:.4g}, non-e10s group median is {:.4g}.\".format(e10s_median, non_e10s_median))\n",
    "            \n",
    "    print(\"\\nThe probability of this difference occurring purely by chance is {:.3f}.\"\\\n",
    "        .format(grouped_permutation_test(median_diff, [e10s_data, non_e10s_data], num_samples=10000)))\n",
    "    \n",
    "    if e10s_std is not None and non_e10s_std is not None:\n",
    "        ## Include a comparison between non-addon cohorts.\n",
    "        e10s_std = e10s_std.dropna()\n",
    "        non_e10s_std = non_e10s_std.dropna()\n",
    "        if len(e10s_std) > 0 and len(non_e10s_std) > 0:\n",
    "            non_e10s_std_median = np.median(non_e10s_std)\n",
    "            mdiff_std = median_diff(e10s_std, non_e10s_std)\n",
    "            print(\"\\nFor cohorts with no add-ons, median with e10s is {:.3g} {} ({:.1f}%) {} median without\"\\\n",
    "                 .format(\n",
    "                    #abs(mdiff_std),\n",
    "                    mdiff_std,\n",
    "                    unit,\n",
    "                    float(mdiff_std) / non_e10s_std_median * 100,\n",
    "                    #\"higher than\" if mdiff_std >= 0 else \"lower than\"\n",
    "                    \"different from\"))\n",
    "\n",
    "    \n",
    "def link_to_histogram(hist_name):\n",
    "    \"\"\" Create a link to the histogram definition in Markdown. \"\"\"\n",
    "    return \"[{}](https://dxr.mozilla.org/mozilla-central/search?q={}+file%3AHistograms.json&redirect=true)\"\\\n",
    "            .format(hist_name, hist_name)\n",
    "\n",
    "def hist_base_name(path_to_histogram):\n",
    "    \"\"\" Remove any path components from histogram name.\n",
    "    \n",
    "        If histogram is specified as a path in the payload, with separator '/',\n",
    "        remove everything but the last component (the actual name).\n",
    "        However, if the histogram is keyed, and specified with a key, return\n",
    "        [histname, key].\n",
    "    \"\"\"\n",
    "    path_to_histogram = path_to_histogram.rsplit(\"/\")\n",
    "    if len(path_to_histogram) > 1 and path_to_histogram[-3] == \"keyedHistograms\":\n",
    "        ## There was a keyedHistogram name and key given.\n",
    "        return path_to_histogram[-2:]\n",
    "    return path_to_histogram[-1]\n",
    "\n",
    "## Hack to render links in code output.\n",
    "from IPython.display import Markdown, display\n",
    "def print_with_markdown(md_text):\n",
    "    \"\"\" Print Markdown text so that it renders correctly in the cell output. \"\"\"\n",
    "    display(Markdown(md_text))\n",
    "\n",
    "def sample_size_str(sample_size, cohort_size=None):\n",
    "    \"\"\" Convert a sample size to a string representation, including a percentage if available. \"\"\"\n",
    "    if sample_size == 0:\n",
    "        return \"No\"\n",
    "    if cohort_size:\n",
    "        if sample_size == cohort_size:\n",
    "            return \"All\"\n",
    "        return \"{} ({:.1f}%)\".format(sample_size, float(sample_size) / cohort_size * 100)\n",
    "    return str(sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get e10s/non-e10s cohorts for the add-ons experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derived dataset is computed from profiles on Beta 50 who have e10sCohort set. It contains a single record (ping) per client, which is randomly selected from among the client's pings during the date range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- clientId: string (nullable = false)\n",
      " |-- e10sCohort: string (nullable = false)\n",
      " |-- creationTimestamp: string (nullable = false)\n",
      " |-- submissionDate: string (nullable = false)\n",
      " |-- documentId: string (nullable = false)\n",
      " |-- sampleId: integer (nullable = false)\n",
      " |-- buildId: string (nullable = false)\n",
      " |-- simpleMeasurements: string (nullable = false)\n",
      " |-- settings: string (nullable = false)\n",
      " |-- addons: string (nullable = false)\n",
      " |-- system: string (nullable = false)\n",
      " |-- build: string (nullable = false)\n",
      " |-- threadHangStats: string (nullable = false)\n",
      " |-- histograms: string (nullable = false)\n",
      " |-- keyedHistograms: string (nullable = false)\n",
      " |-- childPayloads: string (nullable = false)\n",
      " |-- processes: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# regenerated data and loaded into telemetry-test-bucket\n",
    "dataset = sqlContext.read.parquet(\n",
    "    \"s3://telemetry-parquet/e10s_experiment_view/e10s_addons_beta51_cohorts/v20161228_20170104/\")\n",
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many records are in the overall dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2922783"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12669, 1017795)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def has_slow_scripts(hist):\n",
    "    if hist:\n",
    "        hist = json.loads(hist)\n",
    "        if 'SLOW_SCRIPT_PAGE_COUNT' in hist:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "has_slow_scripts = fun.udf(has_slow_scripts, pyspark.sql.types.BooleanType())\n",
    "\n",
    "addons_dataset = dataset.filter(\"e10sCohort like 'addons-set51%'\")\n",
    "\n",
    "addons_dataset_slow = addons_dataset.filter(has_slow_scripts('histograms'))\n",
    "addons_dataset_no_slow = addons_dataset.filter(~has_slow_scripts('histograms'))\n",
    "\n",
    "addons_dataset_slow.count(), addons_dataset_no_slow.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_active_addon_info(addons_str):\n",
    "    \"\"\" Return a list of currently enabled add-ons in the form (GUID, name, isSystem). \"\"\"\n",
    "    addons = json.loads(addons_str)\n",
    "    addons = addons.get(\"activeAddons\", {})\n",
    "    if not addons:\n",
    "        return []\n",
    "    return [(guid, meta.get(\"name\"), meta.get(\"isSystem\")) for guid, meta in addons.iteritems()]\n",
    "\n",
    "\n",
    "def dataset_installed_addons(data, n_top=100):\n",
    "    \"\"\" Extract add-on info from a subset of the main dataset, and generate a table of top add-ons\n",
    "        with installation counts.\n",
    "        \n",
    "        Returns a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    data_addons = data.map(lambda row: row[\"addons\"])\n",
    "    data_addons.cache()\n",
    "    n_in_data = data_addons.count()\n",
    "    \n",
    "    ##  Get counts by add-on ID/name/isSystem value.\n",
    "    addon_counts = data_addons.flatMap(get_active_addon_info)\\\n",
    "        .map(lambda a: (a, 1))\\\n",
    "        .reduceByKey(add)\\\n",
    "        .map(lambda ((guid, name, sys), n): (guid, (name, sys, n)))\n",
    "    \n",
    "    ## Summarize using the most common name and isSystem value.\n",
    "    top_vals = addon_counts.reduceByKey(lambda a, b: a if a[-1] > b[-1] else b)\\\n",
    "        .map(lambda (guid, (name, sys, n)): (guid, (name, sys)))\n",
    "    n_installs = addon_counts.mapValues(lambda (name, sys, n): n)\\\n",
    "        .reduceByKey(add)\n",
    "    addon_info = top_vals.join(n_installs)\\\n",
    "        .map(lambda (guid, ((name, sys), n)): {\n",
    "                \"guid\": guid,\n",
    "                \"name\": name,\n",
    "                \"is_system\": sys,\n",
    "                \"n_installs\": n,\n",
    "                \"pct_installed\": n / n_in_data * 100\n",
    "            })\\\n",
    "        .sortBy(lambda info: info[\"n_installs\"], ascending=False)\n",
    "    \n",
    "    addon_info_coll = addon_info.collect() if not n_top else \\\n",
    "                      addon_info.takeOrdered(n_top, key=lambda x: -x['n_installs'])\n",
    "    addon_info_table = pd.DataFrame(addon_info_coll)\n",
    "    addon_info_table = addon_info_table[[\"guid\", \"name\", \"is_system\", \"n_installs\", \"pct_installed\"]]\n",
    "    ## Number rows from 1.\n",
    "    addon_info_table.index += 1\n",
    "    n_addons = addon_info.count()\n",
    "    data_addons.unpersist()\n",
    "    return (n_addons, addon_info_table)\n",
    "\n",
    "\n",
    "def get_top_addons(data, n_top=25):\n",
    "    addons_cohort_num, addons_cohort_table = dataset_installed_addons(data,n_top=n_top)\n",
    "    addons_cohort_table[\"n_installs\"] = addons_cohort_table[\"n_installs\"].map(\"{:,}\".format)\n",
    "    addons_cohort_table[\"pct_installed\"] = addons_cohort_table[\"pct_installed\"].map(\"{:.2f}\".format)\n",
    "    return addons_cohort_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_slow = get_top_addons(addons_dataset_slow)\n",
    "top_no_slow = get_top_addons(addons_dataset_no_slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distinct_to_slow = set(top_slow.guid) - set(top_no_slow.guid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guid</th>\n",
       "      <th>name</th>\n",
       "      <th>is_system</th>\n",
       "      <th>n_installs</th>\n",
       "      <th>pct_installed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>client@anonymox.net</td>\n",
       "      <td>anonymoX</td>\n",
       "      <td>False</td>\n",
       "      <td>351</td>\n",
       "      <td>2.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   guid      name is_system n_installs pct_installed\n",
       "18  client@anonymox.net  anonymoX     False        351          2.77"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_slow[[i in distinct_to_slow for i in top_slow.guid]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-baad2560648b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistograms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SLOW_SCRIPT_PAGE_COUNT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddons_dataset_slow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'histograms'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-118-baad2560648b>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistograms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SLOW_SCRIPT_PAGE_COUNT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddons_dataset_slow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'histograms'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "ss = map(lambda x: x.histograms['SLOW_SCRIPT_PAGE_COUNT'], addons_dataset_slow.select('histograms').collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the cohorts, and how many clients do we have in each cohort?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 6.63 s\n",
      "\n",
      "Total number of clients: 2,922,783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(u'addons-set49a-test', 2, '0.00%'),\n",
       " (u'addons-set50allmpc-control', 4135, '0.14%'),\n",
       " (u'addons-set50allmpc-test', 4052, '0.14%'),\n",
       " (u'addons-set51alladdons-control', 520261, '17.80%'),\n",
       " (u'addons-set51alladdons-test', 510203, '17.46%'),\n",
       " (u'control', 724008, '24.77%'),\n",
       " (u'disqualified', 15, '0.00%'),\n",
       " (u'disqualified-control', 216598, '7.41%'),\n",
       " (u'disqualified-test', 215042, '7.36%'),\n",
       " (u'optedIn', 5943, '0.20%'),\n",
       " (u'optedOut', 19556, '0.67%'),\n",
       " (u'temp-disqualified-ru', 11, '0.00%'),\n",
       " (u'test', 698302, '23.89%'),\n",
       " (u'unknown', 4576, '0.16%'),\n",
       " (u'unsupportedChannel', 79, '0.00%')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time cohort_counts = dataset.groupby(\"e10sCohort\").count().collect()\n",
    "dataset_count = sum(map(lambda r: r[\"count\"], cohort_counts))\n",
    "\n",
    "def cohort_proportions(r):\n",
    "    prop = r[\"count\"] * 100.0 / dataset_count\n",
    "    return (r[\"e10sCohort\"], r[\"count\"], \"{:.2f}%\".format(prop))\n",
    "\n",
    "print(\"\\nTotal number of clients: {:,}\".format(dataset_count))\n",
    "sorted(map(cohort_proportions, cohort_counts), key = lambda r: r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ADDONS_TEST_COHORT = u'addons-set51alladdons-test'\n",
    "ADDONS_CONTROL_COHORT = u'addons-set51alladdons-control'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restrict to pings belonging to the e10s add-ons experiment. Also include the standard e10s test/control for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addons_exp_dataset = dataset.filter(\\\n",
    "\"e10sCohort in ('%s','%s', 'test', 'control')\" % (ADDONS_TEST_COHORT, ADDONS_CONTROL_COHORT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many clients are left?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2452774"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addons_exp_dataset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make sure that the pings tagged into the cohorts satisfy the basic assumptions of the experiment, as this not guaranteed. All add-ons cohort pings should have active add-ons, and e10s should be enabled if and only if the ping belongs to the test cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def e10s_status_check(settings, addons):\n",
    "    \"\"\" Check whether e10s is enabled, and whether there are add-ons. \"\"\"\n",
    "    e10sEnabled = json.loads(settings).get(\"e10sEnabled\")\n",
    "    active_addons = json.loads(addons).get(\"activeAddons\")\n",
    "    return Row(\n",
    "        e10s_enabled = bool(e10sEnabled), \n",
    "        has_addons = bool(active_addons)\n",
    "    )\n",
    "\n",
    "def bad_ping(cohort, settings, addons):\n",
    "    \"\"\" e10s should be enabled iff the profile is in the test cohort, and profiles should have active add-ons\n",
    "        if they are in the addons cohorts. \n",
    "    \"\"\"\n",
    "    check_data = e10s_status_check(settings, addons)\n",
    "    is_bad = cohort.endswith(\"test\") != check_data.e10s_enabled\n",
    "    if cohort.startswith(\"addons\"):\n",
    "        is_bad = is_bad or not check_data.has_addons\n",
    "    return is_bad\n",
    "\n",
    "## Add a Column to the DF with the outcome of the check.\n",
    "## This will be used to remove any bad rows after examining them.\n",
    "from pyspark.sql.types import BooleanType\n",
    "status_check_udf = fun.udf(bad_ping, BooleanType())\n",
    "addons_exp_dataset_check = addons_exp_dataset.withColumn(\"badPing\",\n",
    "    status_check_udf(addons_exp_dataset.e10sCohort, addons_exp_dataset.settings, addons_exp_dataset.addons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are any bad pings, describe the problems and remove them from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addons_exp_dataset_bad = addons_exp_dataset_check.filter(\"badPing\")\\\n",
    "    .select(\"e10sCohort\", \"settings\", \"addons\")\\\n",
    "    .rdd\n",
    "\n",
    "has_bad = not addons_exp_dataset_bad.isEmpty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issues:\n",
      "(u'addons-set51alladdons-test', Row(e10s_enabled=False, has_addons=False)): 3\n",
      "(u'addons-set51alladdons-control', Row(e10s_enabled=False, has_addons=False)): 1687\n",
      "(u'addons-set51alladdons-test', Row(e10s_enabled=False, has_addons=True)): 95\n",
      "(u'addons-set51alladdons-test', Row(e10s_enabled=True, has_addons=False)): 503\n",
      "(u'addons-set51alladdons-control', Row(e10s_enabled=True, has_addons=True)): 1\n"
     ]
    }
   ],
   "source": [
    "if not has_bad:\n",
    "    print(\"No issues\")\n",
    "else:\n",
    "    check_counts = addons_exp_dataset_bad\\\n",
    "        .map(lambda r: (r.e10sCohort, e10s_status_check(r.settings, r.addons)))\\\n",
    "        .countByValue()\n",
    "    print(\"Issues:\")\n",
    "    for k, v in check_counts.iteritems():\n",
    "        print(\"{}: {}\".format(k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing these pings from the dataset.\n",
      "The dataset now contains 2450485 clients\n"
     ]
    }
   ],
   "source": [
    "if has_bad:\n",
    "    print(\"\\nRemoving these pings from the dataset.\")\n",
    "    addons_exp_dataset = addons_exp_dataset_check.filter(\"not badPing\").drop(\"badPing\")\n",
    "    print(\"The dataset now contains {} clients\".format(addons_exp_dataset.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Dataframe to RDD of pings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Comparison for count histogram SLOW_SCRIPT_PAGE_COUNT (with add-ons):"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2347 non-e10s profiles have this histogram.\n",
      "3057 e10s profiles have this histogram.\n",
      "\n",
      "Comparison for SLOW_SCRIPT_PAGE_COUNT per hour (with add-ons):\n",
      "\n",
      "- Median with e10s is 0.062 units different from median without e10s.\n",
      "- This is a relative difference of 22.8%.\n",
      "- E10s group median is 0.3337, non-e10s group median is 0.2717.\n",
      "\n",
      "The probability of this difference occurring purely by chance is 0.002.\n",
      "\n",
      "For cohorts with no add-ons, median with e10s is 0.0214 units (7.0%) different from median without\n"
     ]
    }
   ],
   "source": [
    "compare_count_histograms(subset, \"payload/histograms/SLOW_SCRIPT_PAGE_COUNT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are there add-ons that correlate with Slow Scripts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addons_subset = addons_exp_dataset.filter(\"e10sCohort like '%addons\")   \n",
    "slow = 'SLOW_SCRIPT_PAGE_COUNT'\n",
    "addons_subset_slow = addons_subset.filter(lambda x: x['payload']['histograms'].get(slow) is not None)\n",
    "addons_subset_no_slow = addons_subset.filter(lambda x: x['payload']['histograms'].get(slow) is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# profiles with addons and slow scripts: 11886\n",
      "# profiles with addons and no slow scripts: 924922\n"
     ]
    }
   ],
   "source": [
    "print '# profiles with addons and slow scripts:', addons_subset_slow.count()\n",
    "print '# profiles with addons and no slow scripts:', addons_subset_no_slow.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_active_addon_info(addons_str):\n",
    "    \"\"\" Return a list of currently enabled add-ons in the form (GUID, name, isSystem). \"\"\"\n",
    "    addons = json.loads(addons_str)\n",
    "    addons = addons.get(\"activeAddons\", {})\n",
    "    if not addons:\n",
    "        return []\n",
    "    return [(guid, meta.get(\"name\"), meta.get(\"isSystem\")) for guid, meta in addons.iteritems()]\n",
    "\n",
    "\n",
    "def dataset_installed_addons(data, n_top=100):\n",
    "    \"\"\" Extract add-on info from a subset of the main dataset, and generate a table of top add-ons\n",
    "        with installation counts.\n",
    "        \n",
    "        Returns a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    data_addons = data.map(lambda row: row[\"addons\"])\n",
    "    data_addons.cache()\n",
    "    n_in_data = data_addons.count()\n",
    "    \n",
    "    ##  Get counts by add-on ID/name/isSystem value.\n",
    "    addon_counts = data_addons.flatMap(get_active_addon_info)\\\n",
    "        .map(lambda a: (a, 1))\\\n",
    "        .reduceByKey(add)\\\n",
    "        .map(lambda ((guid, name, sys), n): (guid, (name, sys, n)))\n",
    "    \n",
    "    ## Summarize using the most common name and isSystem value.\n",
    "    top_vals = addon_counts.reduceByKey(lambda a, b: a if a[-1] > b[-1] else b)\\\n",
    "        .map(lambda (guid, (name, sys, n)): (guid, (name, sys)))\n",
    "    n_installs = addon_counts.mapValues(lambda (name, sys, n): n)\\\n",
    "        .reduceByKey(add)\n",
    "    addon_info = top_vals.join(n_installs)\\\n",
    "        .map(lambda (guid, ((name, sys), n)): {\n",
    "                \"guid\": guid,\n",
    "                \"name\": name,\n",
    "                \"is_system\": sys,\n",
    "                \"n_installs\": n,\n",
    "                \"pct_installed\": n / n_in_data * 100\n",
    "            })\\\n",
    "        .sortBy(lambda info: info[\"n_installs\"], ascending=False)\n",
    "    \n",
    "    addon_info_coll = addon_info.collect() if not n_top else addon_info.take(n_top)\n",
    "    addon_info_table = pd.DataFrame(addon_info_coll)\n",
    "    addon_info_table = addon_info_table[[\"guid\", \"name\", \"is_system\", \"n_installs\", \"pct_installed\"]]\n",
    "    ## Number rows from 1.\n",
    "    addon_info_table.index += 1\n",
    "    n_addons = addon_info.count()\n",
    "    data_addons.unpersist()\n",
    "    return (n_addons, addon_info_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 176 in stage 208.0 failed 4 times, most recent failure: Lost task 176.3 in stage 208.0 (TID 51180, ip-172-31-12-248.us-west-2.compute.internal): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/mnt/yarn/usercache/hadoop/appcache/application_1484077641424_0001/container_1484077641424_0001_01_000013/pyspark.zip/pyspark/worker.py\", line 111, in main\n    process()\n  File \"/mnt/yarn/usercache/hadoop/appcache/application_1484077641424_0001/container_1484077641424_0001_01_000013/pyspark.zip/pyspark/worker.py\", line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2346, in pipeline_func\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2346, in pipeline_func\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 317, in func\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 1776, in combineLocally\n  File \"/mnt/yarn/usercache/hadoop/appcache/application_1484077641424_0001/container_1484077641424_0001_01_000013/pyspark.zip/pyspark/shuffle.py\", line 236, in mergeValues\n    for k, v in iterator:\n  File \"<ipython-input-47-8af986536817>\", line 3, in get_active_addon_info\nTypeError: Expected String or Unicode\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:342)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1845)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1858)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1929)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:927)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:926)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:405)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.GeneratedMethodAccessor123.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/mnt/yarn/usercache/hadoop/appcache/application_1484077641424_0001/container_1484077641424_0001_01_000013/pyspark.zip/pyspark/worker.py\", line 111, in main\n    process()\n  File \"/mnt/yarn/usercache/hadoop/appcache/application_1484077641424_0001/container_1484077641424_0001_01_000013/pyspark.zip/pyspark/worker.py\", line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2346, in pipeline_func\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2346, in pipeline_func\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 317, in func\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 1776, in combineLocally\n  File \"/mnt/yarn/usercache/hadoop/appcache/application_1484077641424_0001/container_1484077641424_0001_01_000013/pyspark.zip/pyspark/shuffle.py\", line 236, in mergeValues\n    for k, v in iterator:\n  File \"<ipython-input-47-8af986536817>\", line 3, in get_active_addon_info\nTypeError: Expected String or Unicode\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:342)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-4ab033b2a08e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m addons_cohort_num, addons_cohort_table = dataset_installed_addons(\n\u001b[1;32m      3\u001b[0m     \u001b[0maddons_subset_slow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     n_top=50)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"There were {:,} distinct add-ons installed across the addons cohort.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddons_cohort_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-8af986536817>\u001b[0m in \u001b[0;36mdataset_installed_addons\u001b[0;34m(data, n_top)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;34m\"pct_installed\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_in_data\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             })\\\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;34m.\u001b[0m\u001b[0msortBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n_installs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0maddon_info_coll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maddon_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn_top\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0maddon_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_top\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36msortBy\u001b[0;34m(self, keyfunc, ascending, numPartitions)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \"\"\"\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msortByKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumPartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mglom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36msortByKey\u001b[0;34m(self, ascending, numPartitions, keyfunc)\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;31m# the key-space into bins such that the bins have roughly the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;31m# number of (key, value) pairs falling into them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m         \u001b[0mrddSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrddSize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m  \u001b[0;31m# empty RDD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \"\"\"\n\u001b[0;32m-> 1004\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;36m6.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m         \"\"\"\n\u001b[0;32m--> 995\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mfold\u001b[0;34m(self, zeroValue, op)\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;31m# zeroValue provided to each partition is unique from the one provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;31m# to the final reduce call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeroValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \"\"\"\n\u001b[1;32m    770\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         return_value = get_return_value(\n\u001b[0;32m--> 813\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    306\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    307\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 176 in stage 208.0 failed 4 times, most recent failure: Lost task 176.3 in stage 208.0 (TID 51180, ip-172-31-12-248.us-west-2.compute.internal): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/mnt/yarn/usercache/hadoop/appcache/application_1484077641424_0001/container_1484077641424_0001_01_000013/pyspark.zip/pyspark/worker.py\", line 111, in main\n    process()\n  File \"/mnt/yarn/usercache/hadoop/appcache/application_1484077641424_0001/container_1484077641424_0001_01_000013/pyspark.zip/pyspark/worker.py\", line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2346, in pipeline_func\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2346, in pipeline_func\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 317, in func\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 1776, in combineLocally\n  File \"/mnt/yarn/usercache/hadoop/appcache/application_1484077641424_0001/container_1484077641424_0001_01_000013/pyspark.zip/pyspark/shuffle.py\", line 236, in mergeValues\n    for k, v in iterator:\n  File \"<ipython-input-47-8af986536817>\", line 3, in get_active_addon_info\nTypeError: Expected String or Unicode\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:342)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1845)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1858)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1929)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:927)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:926)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:405)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.GeneratedMethodAccessor123.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/mnt/yarn/usercache/hadoop/appcache/application_1484077641424_0001/container_1484077641424_0001_01_000013/pyspark.zip/pyspark/worker.py\", line 111, in main\n    process()\n  File \"/mnt/yarn/usercache/hadoop/appcache/application_1484077641424_0001/container_1484077641424_0001_01_000013/pyspark.zip/pyspark/worker.py\", line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2346, in pipeline_func\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2346, in pipeline_func\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 317, in func\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 1776, in combineLocally\n  File \"/mnt/yarn/usercache/hadoop/appcache/application_1484077641424_0001/container_1484077641424_0001_01_000013/pyspark.zip/pyspark/shuffle.py\", line 236, in mergeValues\n    for k, v in iterator:\n  File \"<ipython-input-47-8af986536817>\", line 3, in get_active_addon_info\nTypeError: Expected String or Unicode\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:342)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "\n",
    "addons_cohort_num_slow, addons_cohort_table_slow = dataset_installed_addons(\n",
    "    addons_subset_slow,\n",
    "    n_top=50)\n",
    "print(\"There were {:,} distinct add-ons installed across the addons cohort.\".format(addons_cohort_num))\n",
    "\n",
    "addons_cohort_table_slow[\"n_installs\"] = addons_cohort_table_slow[\"n_installs\"].map(\"{:,}\".format)\n",
    "addons_cohort_table_slow[\"pct_installed\"] = addons_cohort_table_slow[\"pct_installed\"].map(\"{:.2f}\".format)\n",
    "addons_cohort_table_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addons_subset_slow.map(lambda x: x['addons']).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
