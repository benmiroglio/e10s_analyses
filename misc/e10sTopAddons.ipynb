{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of Top Addons in e10sCohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = sqlContext.read.parquet(\n",
    "    \"s3://telemetry-parquet/e10s_experiment_view/e10s_addons_beta51_cohorts/v20161207_20161214/\")\n",
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check cohort names and sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time cohort_counts = dataset.groupby(\"e10sCohort\").count().collect()\n",
    "dataset_count = sum(map(lambda r: r[\"count\"], cohort_counts))\n",
    "\n",
    "def cohort_proportions(r):\n",
    "    prop = r[\"count\"] * 100.0 / dataset_count\n",
    "    return (r[\"e10sCohort\"], r[\"count\"], \"{:.2f}%\".format(prop))\n",
    "\n",
    "print(\"\\nTotal number of clients: {:,}\".format(dataset_count))\n",
    "sorted(map(cohort_proportions, cohort_counts), key = lambda r: r[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restrict to e10s experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addons_exp_dataset = dataset.filter(\n",
    "        \"e10sCohort in ('addons-set51alladdons-test', 'addons-set51alladdons-control', 'test', 'control')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove bad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def e10s_status_check(settings, addons):\n",
    "    \"\"\" Check whether e10s is enabled, and whether there are add-ons. \"\"\"\n",
    "    e10sEnabled = json.loads(settings).get(\"e10sEnabled\")\n",
    "    active_addons = json.loads(addons).get(\"activeAddons\")\n",
    "    return Row(\n",
    "        e10s_enabled = bool(e10sEnabled), \n",
    "        has_addons = bool(active_addons)\n",
    "    )\n",
    "\n",
    "def bad_ping(cohort, settings, addons):\n",
    "    \"\"\" e10s should be enabled iff the profile is in the test cohort, and profiles should have active add-ons\n",
    "        if they are in the addons cohorts. \n",
    "    \"\"\"\n",
    "    check_data = e10s_status_check(settings, addons)\n",
    "    is_bad = cohort.endswith(\"test\") != check_data.e10s_enabled\n",
    "    if cohort.startswith(\"addons\"):\n",
    "        is_bad = is_bad or not check_data.has_addons\n",
    "    return is_bad\n",
    "\n",
    "## Add a Column to the DF with the outcome of the check.\n",
    "## This will be used to remove any bad rows after examining them.\n",
    "from pyspark.sql.types import BooleanType\n",
    "status_check_udf = fun.udf(bad_ping, BooleanType())\n",
    "addons_exp_dataset_check = addons_exp_dataset.withColumn(\"badPing\",\n",
    "    status_check_udf(addons_exp_dataset.e10sCohort, addons_exp_dataset.settings, addons_exp_dataset.addons))\n",
    "\n",
    "addons_exp_dataset_bad = addons_exp_dataset_check.filter(\"badPing\")\\\n",
    "    .select(\"e10sCohort\", \"settings\", \"addons\")\\\n",
    "    .rdd\n",
    "\n",
    "has_bad = not addons_exp_dataset_bad.isEmpty()\n",
    "\n",
    "if not has_bad:\n",
    "    print(\"No issues\")\n",
    "else:\n",
    "    check_counts = addons_exp_dataset_bad\\\n",
    "        .map(lambda r: (r.e10sCohort, e10s_status_check(r.settings, r.addons)))\\\n",
    "        .countByValue()\n",
    "    print(\"Issues:\")\n",
    "    for k, v in check_counts.iteritems():\n",
    "        print(\"{}: {}\".format(k, v))\n",
    "        \n",
    "if has_bad:\n",
    "    print(\"\\nRemoving these pings from the dataset.\")\n",
    "    addons_exp_dataset = addons_exp_dataset_check.filter(\"not badPing\").drop(\"badPing\")\n",
    "    print(\"The dataset now contains {} clients\".format(addons_exp_dataset.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get add-on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_active_addon_info(addons_str):\n",
    "    \"\"\" Return a list of currently enabled add-ons in the form (GUID, name, version, isSystem). \"\"\"\n",
    "    addons = json.loads(addons_str)\n",
    "    addons = addons.get(\"activeAddons\", {})\n",
    "    if not addons:\n",
    "        return []\n",
    "    return [(guid, meta.get(\"name\"), meta.get(\"isSystem\"), meta.get('version')) for guid, meta in addons.iteritems()]\n",
    "\n",
    "\n",
    "def dataset_installed_addons(data, n_top=100):\n",
    "    \"\"\" Extract add-on info from a subset of the main dataset, and generate a table of top add-ons\n",
    "        with installation counts.\n",
    "        \n",
    "        Returns a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    data_addons = data.select(\"addons\").rdd.map(lambda row: row[\"addons\"])\n",
    "    data_addons.cache()\n",
    "    n_in_data = data_addons.count()\n",
    "    \n",
    "    ##  Get counts by add-on ID/name/isSystem value.\n",
    "    addon_counts = data_addons.flatMap(get_active_addon_info)\\\n",
    "        .map(lambda a: (a, 1))\\\n",
    "        .reduceByKey(add)\\\n",
    "        .map(lambda ((guid, name, sys, version), n): (guid, (name, sys, version, n)))\n",
    "    \n",
    "    ## Summarize using the most common name and isSystem value.\n",
    "    top_vals = addon_counts.reduceByKey(lambda a, b: a if a[-1] > b[-1] else b)\\\n",
    "        .map(lambda (guid, (name, sys, version, n)): (guid, (name, sys, version)))\n",
    "    n_installs = addon_counts.mapValues(lambda (name, sys, version, n): n)\\\n",
    "        .reduceByKey(add)\n",
    "    addon_info = top_vals.join(n_installs)\\\n",
    "        .map(lambda (guid, ((name, sys, version), n)): {\n",
    "                \"guid\": guid,\n",
    "                \"name\": name,\n",
    "                \"is_system\": sys,\n",
    "                \"version\":version,\n",
    "                \"n_installs\": n,\n",
    "                \"pct_installed\": n / n_in_data * 100\n",
    "            })\\\n",
    "        .sortBy(lambda info: info[\"n_installs\"], ascending=False)\n",
    "    \n",
    "    addon_info_coll = addon_info.collect() if not n_top else addon_info.take(n_top)\n",
    "    addon_info_table = pd.DataFrame(addon_info_coll)\n",
    "    addon_info_table = addon_info_table[[\"guid\", \"name\", \"version\",\"is_system\", \"n_installs\", \"pct_installed\"]]\n",
    "    ## Number rows from 1.\n",
    "    addon_info_table.index += 1\n",
    "    n_addons = addon_info.count()\n",
    "    data_addons.unpersist()\n",
    "    return (n_addons, addon_info_table)\n",
    "\n",
    "addons_cohort_num, addons_cohort_table = dataset_installed_addons(\n",
    "    addons_exp_dataset.filter(\"e10sCohort like 'addons%'\"),\n",
    "    n_top=100)\n",
    "print(\"There were {:,} distinct add-ons installed across the addons cohort.\".format(addons_cohort_num))\n",
    "\n",
    "addons_cohort_table[\"n_installs\"] = addons_cohort_table[\"n_installs\"].map(\"{:,}\".format)\n",
    "addons_cohort_table[\"pct_installed\"] = addons_cohort_table[\"pct_installed\"].map(\"{:.2f}\".format)\n",
    "addons_cohort_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up add-on names (funky characters) and write to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean and output top addons to csv\n",
    "def clean_column(col):\n",
    "    '''cleans up non-ascii characters'''\n",
    "    clean = []\n",
    "    for elem in col:\n",
    "        try:\n",
    "            elem = str(elem)\n",
    "            clean.append(elem)\n",
    "        except UnicodeEncodeError:\n",
    "            try:\n",
    "                elem = elem.encode('utf8')\n",
    "                clean.append(elem)\n",
    "            except Exception as e:\n",
    "                raise ValueError('{} is causing the following error\\n: {}'.format(elem, e))\n",
    "                break\n",
    "    return clean\n",
    "\n",
    "addons_cohort_table['name'] = clean_column(addons_cohort_table['name'])\n",
    "addons_cohort_table.to_csv('beta51-top25-addons.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
